# 车载多模态交互系统 - 视觉交互部分需求分析

## 1. 项目概述

### 1.1 项目背景

随着智能驾驶技术的发展，车载人机交互系统面临着新的挑战与机遇。传统的按钮和触摸屏交互方式在驾驶过程中可能分散驾驶员注意力，增加安全风险。本项目旨在开发一种基于视觉的多模态交互系统，通过眼动追踪、头部姿态识别和手势识别技术，实现驾驶员与车载系统的自然、安全和高效交互，同时提供分心检测和预警功能，提升驾驶安全性。

### 1.2 项目目标

1. 开发一套完整的车载视觉交互系统，融合眼动追踪、头部姿态识别和手势识别三种模态
2. 基于GazeCapture数据集训练高精度的眼动追踪模型，实现注视点预测和分心状态检测
3. 构建实时、鲁棒的多模态融合决策机制，适应各种驾驶环境和用户操作习惯
4. 设计直观的人机交互界面，支持视觉反馈和多级预警机制
5. 优化系统性能，确保在车载环境中高效稳定运行

### 1.3 适用范围

本需求规格说明适用于：
- 项目开发团队成员
- 项目测试人员
- 系统集成商
- 合作伙伴和客户代表

## 2. 功能需求

### 2.1 眼动追踪功能

#### 2.1.1 眼部检测与跟踪

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-ET-001 | 系统应能在视频流中实时检测和跟踪驾驶员的眼睛位置 | 高 |
| FR-ET-002 | 系统应能在不同光照条件下（白天、夜间、隧道）保持眼部检测稳定性 | 高 |
| FR-ET-003 | 系统应支持佩戴眼镜（包括太阳镜）用户的眼部检测 | 中 |
| FR-ET-004 | 系统应能处理部分遮挡情况下的眼部检测 | 中 |

#### 2.1.2 注视点预测

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-ET-005 | 系统应能基于GazeCapture数据集训练的模型预测驾驶员注视点位置 | 高 |
| FR-ET-006 | 注视点预测平均角度误差应小于3度（在验证集上测试） | 高 |
| FR-ET-007 | 系统应能以至少25fps的速度进行实时注视点预测 | 高 |
| FR-ET-008 | 系统应能将注视点映射到车内区域（仪表盘、中控屏、后视镜等） | 中 |

#### 2.1.3 分心状态检测

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-ET-009 | 系统应能检测驾驶员视线是否离开道路前方超过预设阈值时间 | 高 |
| FR-ET-010 | 系统应能根据车速和驾驶环境动态调整分心判断阈值（高速公路更严格） | 中 |
| FR-ET-011 | 系统应支持区分短暂查看仪表盘/后视镜与真正分心行为 | 高 |
| FR-ET-012 | 系统应记录分心事件，包括持续时间、频率和严重程度 | 低 |

### 2.2 头部姿态识别功能

#### 2.2.1 人脸检测与姿态估计

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-HP-001 | 系统应能实时检测驾驶员面部并估计头部三维姿态（俯仰角、偏航角、翻滚角） | 高 |
| FR-HP-002 | 头部姿态估计应在±15度范围内误差不超过3度 | 中 |
| FR-HP-003 | 系统应在佩戴口罩、帽子等情况下保持姿态估计功能 | 中 |
| FR-HP-004 | 系统应以至少30fps的速度进行实时头部姿态估计 | 高 |

#### 2.2.2 头部动作识别

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-HP-005 | 系统应能识别点头动作（用于确认）并准确区分有意点头与路面颠簸导致的头部晃动 | 高 |
| FR-HP-006 | 系统应能识别摇头动作（用于拒绝）并准确区分有意摇头与观察路况导致的头部转动 | 高 |
| FR-HP-007 | 系统应能在动作开始后0.8秒内完成动作识别 | 中 |
| FR-HP-008 | 系统应支持用户自定义头部动作灵敏度设置 | 低 |

### 2.3 手势识别功能

#### 2.3.1 手部检测与跟踪

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-GR-001 | 系统应能在视频流中检测和跟踪驾驶员的手部位置 | 高 |
| FR-GR-002 | 系统应支持在方向盘附近区域和中控台区域的手部检测 | 高 |
| FR-GR-003 | 系统应在不同光照条件下保持手部检测稳定性 | 中 |
| FR-GR-004 | 系统应以至少25fps的速度进行实时手部检测 | 高 |

#### 2.3.2 手势分类

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-GR-005 | 系统应能识别握拳手势（用于暂停/停止功能） | 高 |
| FR-GR-006 | 系统应能识别竖起大拇指手势（用于确认功能） | 高 |
| FR-GR-007 | 系统应能识别摇手手势（用于拒绝/取消功能） | 高 |
| FR-GR-008 | 手势识别准确率应不低于90%（在测试集上验证） | 高 |
| FR-GR-009 | 系统应在手势开始后1秒内完成手势识别 | 中 |
| FR-GR-010 | 系统应支持扩展新的手势类型，无需修改核心架构 | 低 |

### 2.4 多模态融合功能

#### 2.4.1 数据同步与融合

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-MF-001 | 系统应确保眼动、头部姿态和手势数据在时间上同步，时差不超过100ms | 高 |
| FR-MF-002 | 系统应实现多模态数据的特征级和决策级融合，提高交互识别鲁棒性 | 高 |
| FR-MF-003 | 系统应能处理单一模态暂时失效情况，保持基本功能可用 | 高 |
| FR-MF-004 | 系统应根据当前场景和历史数据动态调整各模态的权重 | 中 |

#### 2.4.2 状态管理与决策

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-MF-005 | 系统应维护一个全局状态管理器，跟踪用户意图和系统响应状态 | 高 |
| FR-MF-006 | 系统应能在多模态输入出现冲突时（如头部点头但手势拒绝）基于规则或置信度解决冲突 | 高 |
| FR-MF-007 | 系统应支持上下文感知，理解连续交互序列中的用户意图 | 中 |
| FR-MF-008 | 系统应提供可配置的决策规则，允许根据特定应用场景定制 | 低 |

### 2.5 交互反馈与预警功能

#### 2.5.1 视觉反馈

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-FB-001 | 系统应在检测到用户注视中控屏时提供视觉强调效果（如高亮当前注视区域） | 中 |
| FR-FB-002 | 系统应在识别到手势时提供即时视觉反馈，确认已接收到用户输入 | 高 |
| FR-FB-003 | 系统应支持基于注视点的无接触UI元素选择（注视+确认手势或点头） | 中 |

#### 2.5.2 分心预警

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| FR-FB-004 | 系统应实现多级分心预警机制，包括视觉、声音和触觉反馈 | 高 |
| FR-FB-005 | 系统应根据分心持续时间逐级升级预警强度 | 高 |
| FR-FB-006 | 系统应支持用户通过头部动作或手势确认并解除预警 | 高 |
| FR-FB-007 | 系统应能在极端分心情况下触发自动紧急措施（如自动减速，仅适用于高级辅助驾驶模式） | 低 |

## 3. 非功能需求

### 3.1 性能需求

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| NF-PF-001 | 视觉处理系统总体延迟应小于200ms（从图像采集到结果输出） | 高 |
| NF-PF-002 | 系统应支持在四核处理器、4GB RAM的车载计算平台上运行 | 高 |
| NF-PF-003 | 系统在正常运行状态下CPU占用率应不超过30%，GPU占用率不超过40% | 中 |
| NF-PF-004 | 系统应在1分钟内完成启动和初始化 | 中 |
| NF-PF-005 | 对于分心检测，系统假阳性率应低于5%，假阴性率应低于2% | 高 |

### 3.2 可靠性需求

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| NF-RL-001 | 系统平均无故障运行时间(MTBF)应不少于10,000小时 | 高 |
| NF-RL-002 | 系统应在任何单一摄像头失效情况下保持基本功能 | 高 |
| NF-RL-003 | 系统应在环境条件突变（如隧道进出口）时平稳过渡，不丢失跟踪 | 中 |
| NF-RL-004 | 系统应提供自诊断功能，检测硬件和软件异常 | 中 |
| NF-RL-005 | 系统应支持热备份和状态恢复机制 | 低 |

### 3.3 安全性与隐私需求

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| NF-SC-001 | 系统应遵循"隐私设计原则"，视觉数据应优先在本地处理，减少数据传输 | 高 |
| NF-SC-002 | 系统不应永久存储任何可识别驾驶员身份的图像或视频数据 | 高 |
| NF-SC-003 | 必要的数据传输应采用端到端加密，符合汽车行业安全标准 | 高 |
| NF-SC-004 | 系统应允许用户完全禁用数据收集功能 | 中 |
| NF-SC-005 | 系统应符合相关地区的数据保护法规（如GDPR、CCPA等） | 高 |

### 3.4 可用性与人因工程需求

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| NF-US-001 | 系统应提供简洁的用户引导，帮助新用户理解视觉交互机制 | 高 |
| NF-US-002 | 系统应适应不同身高和坐姿的驾驶员，无需复杂设置 | 高 |
| NF-US-003 | 系统应支持白天和夜间模式，自动切换界面亮度和颜色 | 中 |
| NF-US-004 | 系统的视觉反馈应足够明显但不刺眼，避免分散驾驶员注意力 | 高 |
| NF-US-005 | 系统预警应采用多级渐进式设计，避免用户警告疲劳 | 中 |

### 3.5 可维护性与可扩展性需求

| 需求ID | 需求描述 | 优先级 |
|-------|---------|------|
| NF-MT-001 | 系统应采用模块化设计，各功能子系统可独立更新 | 高 |
| NF-MT-002 | 系统应提供标准API接口，方便与其他车载系统集成 | 高 |
| NF-MT-003 | 系统应支持OTA（空中下载）更新，无需硬件干预 | 中 |
| NF-MT-004 | 系统应提供详细日志记录，便于故障诊断和性能分析 | 中 |
| NF-MT-005 | 系统应支持插件架构，允许第三方开发者扩展功能 | 低 |

## 4. 系统限制与约束

### 4.1 硬件限制

- 系统必须在车载环境中的嵌入式平台上运行
- 系统必须使用车载摄像头作为主要输入设备
- 系统必须在车辆振动、颠簸条件下保持稳定工作
- 系统性能在极端温度环境（-20°C至60°C）下可能有所降低

### 4.2 软件限制

- 系统必须与现有车载操作系统兼容
- 系统不应占用超过规定的系统资源
- 系统运行不应影响其他关键车载系统的性能
- 系统必须符合汽车软件安全等级要求（ASIL-B或更高）

### 4.3 法规与标准约束

- 系统必须符合相关地区的道路安全法规
- 系统必须遵循ISO 26262功能安全标准
- 系统必须通过汽车电磁兼容性(EMC)测试
- 系统收集和处理的数据必须符合隐私保护法规

## 5. 验收标准

### 5.1 眼动追踪验收标准

1. 在标准测试环境下，眼动追踪模型平均角度误差不超过2.5度
2. 在95%的测试用例中，分心检测准确率不低于95%
3. 在模拟驾驶环境中，系统能够在不同光照条件下保持稳定的眼部检测率（>90%）
4. 注视点预测延迟不超过100ms

### 5.2 头部姿态识别验收标准

1. 在标准测试环境下，头部姿态估计平均误差不超过3度
2. 在90%的测试用例中，点头和摇头动作识别准确率不低于96%
3. 在真实车辆行驶过程中，系统能够准确区分有意头部动作与道路颠簸导致的头部晃动
4. 头部动作识别延迟不超过800ms

### 5.3 手势识别验收标准

1. 在标准测试环境下，三种核心手势识别准确率不低于94%
2. 在90%的测试用例中，手势识别延迟不超过1秒
3. 在真实驾驶场景中，系统误识率不超过5%
4. 系统能够在驾驶员佩戴手套状态下保持基本手势识别功能

### 5.4 多模态融合验收标准

1. 在模拟驾驶环境中，多模态交互正确率不低于92%
2. 在任一单一模态暂时失效的情况下，系统仍可保持基本功能
3. 系统能够正确解决90%以上的多模态冲突场景
4. 融合决策延迟不超过200ms

### 5.5 系统性能验收标准

1. 在指定硬件平台上，系统总体资源占用不超过规定限制
2. 在连续72小时稳定运行测试中，系统不出现崩溃或内存泄漏
3. 在真实驾驶环境中，系统假阳性率低于5%，假阴性率低于2%
4. 系统启动时间不超过1分钟

## 6. 用户故事与场景

### 6.1 分心检测场景

**用户故事**：作为一名长途驾驶的司机，我希望系统能监测我的注意力状态，在我分心时提醒我，这样我可以及时将注意力重新集中到道路上，避免危险。

**场景描述**：
1. 司机正在高速公路上驾驶，车速为120km/h
2. 司机接听电话，视线从前方路况转向中控台区域
3. 系统检测到视线偏离超过3秒，触发第一级警告（仪表盘指示灯闪烁）
4. 司机继续分心，系统在5秒后触发第二级警告（加入声音提示）
5. 司机通过点头或重新注视前方道路确认警告
6. 系统解除警告状态，记录本次分心事件

### 6.2 多模态交互场景

**用户故事**：作为一名喜欢听音乐的驾驶员，我希望能在不触摸屏幕的情况下控制音乐播放，这样我可以在驾驶时保持安全，同时享受音乐。

**场景描述**：
1. 司机在驾驶过程中想调整音乐
2. 司机注视中控屏幕音乐播放区域
3. 系统检测到注视方向，高亮音乐播放控制界面
4. 司机使用握拳手势暂停音乐
5. 系统识别手势，执行暂停操作并提供视觉反馈
6. 司机后续通过摇手手势切换到下一首
7. 系统在整个过程中持续监控驾驶员注意力状态，确保安全

### 6.3 警告确认场景

**用户故事**：作为一名经常在城市道路驾驶的用户，我希望能以自然的方式快速确认系统警告，而不需要寻找物理按钮，这样我可以更专注于复杂的交通环境。

**场景描述**：
1. 系统检测到潜在危险（如疲劳驾驶迹象）并发出警告
2. 警告通过视觉和声音方式呈现
3. 驾驶员通过向系统竖起大拇指手势确认已收到警告
4. 系统识别确认手势，降低警告级别但保持监控
5. 如果状况改善（如疲劳缓解），系统自动解除警告
6. 如果状况持续，系统在适当时间后重新升级警告级别

## 7. 数据字典

### 7.1 眼动数据

| 数据项 | 描述 | 类型 | 单位/范围 |
|-------|------|------|---------|
| EyePosition | 眼睛在图像中的位置 | 坐标点(x,y) | 像素 |
| GazeDirection | 视线方向向量 | 三维向量(x,y,z) | 归一化单位向量 |
| GazePoint | 注视点在参考平面上的位置 | 坐标点(x,y) | 归一化坐标[-1,1] |
| FixationDuration | 注视持续时间 | 浮点数 | 毫秒(ms) |
| IsLookingRoad | 是否注视道路区域 | 布尔值 | True/False |
| DistractionLevel | 分心程度评分 | 整数 | 0-10 |
| DistractionDuration | 分心持续时间 | 浮点数 | 秒(s) |

### 7.2 头部姿态数据

| 数据项 | 描述 | 类型 | 单位/范围 |
|-------|------|------|---------|
| HeadPosition | 头部在图像中的位置 | 坐标点(x,y) | 像素 |
| HeadPose | 头部三维姿态角度 | 三维向量(pitch,yaw,roll) | 度(°) |
| HeadMovement | 头部移动速度 | 浮点数 | 度/秒(°/s) |
| NodConfidence | 点头动作置信度 | 浮点数 | 0.0-1.0 |
| ShakeConfidence | 摇头动作置信度 | 浮点数 | 0.0-1.0 |
| HeadGesture | 当前检测到的头部姿态类型 | 枚举 | {NORMAL, NODDING, SHAKING, UNKNOWN} |

### 7.3 手势数据

| 数据项 | 描述 | 类型 | 单位/范围 |
|-------|------|------|---------|
| HandPosition | 手部在图像中的位置 | 坐标点(x,y) | 像素 |
| HandLandmarks | 手部关键点位置集合 | 坐标点数组 | 像素 |
| GestureType | 当前检测到的手势类型 | 枚举 | {NORMAL, FIST, THUMBS_UP, WAVE, UNKNOWN} |
| GestureConfidence | 手势识别置信度 | 浮点数 | 0.0-1.0 |
| GestureDuration | 手势持续时间 | 浮点数 | 毫秒(ms) |
| MovementTrajectory | 手部移动轨迹 | 坐标点数组 | 像素 |

### 7.4 系统状态数据

| 数据项 | 描述 | 类型 | 单位/范围 |
|-------|------|------|---------|
| SystemMode | 当前系统工作模式 | 枚举 | {NORMAL, WARNING, CRITICAL, CALIBRATION} |
| WarningLevel | 当前警告级别 | 整数 | 0-3 |
| WarningType | 警告类型 | 枚举 | {NONE, DISTRACTION, FATIGUE, SYSTEM_ERROR} |
| UserIntent | 推断的用户意图 | 枚举 | {NONE, CONFIRM, DECLINE, PAUSE, RESUME} |
| ConfidenceScore | 当前状态置信度 | 浮点数 | 0.0-1.0 |
| InteractionContext | 当前交互上下文 | 字符串 | - |

## 8. 外部接口需求

### 8.1 硬件接口

1. **摄像头接口**：系统应支持连接车载摄像头，分辨率不低于720p，帧率不低于30fps
2. **处理单元接口**：系统应支持连接车载计算平台，通过标准总线通信
3. **显示接口**：系统应能将结果输出到车载显示屏，支持HDMI或类似标准

### 8.2 软件接口

1. **车载操作系统接口**：系统应提供与主流车载操作系统（如Android Automotive、QNX）的兼容层
2. **应用程序接口**：系统应提供REST API或类似接口，允许其他车载应用调用视觉交互功能
3. **数据交换接口**：系统应提供标准化数据格式，用于与车载信息娱乐系统、导航系统等交换数据

### 8.3 通信接口

1. **车载网络接口**：系统应支持通过CAN总线、以太网等与车辆其他系统通信
2. **移动设备接口**：系统应支持与用户移动设备（如智能手机）的通信，用于个性化配置
3. **云服务接口**：系统应支持（可选）与云服务器通信，用于模型更新和匿名数据分析

## 9. 附录

### 9.1 术语表

| 术语 | 定义 |
|------|------|
| 眼动追踪 | 检测和分析用户眼睛运动以确定其注视点的技术 |
| 注视点 | 用户视线在特定平面（如屏幕）上的交点 |
| 分心检测 | 监测驾驶员视线是否离开道路的过程 |
| 头部姿态 | 头部在三维空间中的方向，通常用俯仰角(pitch)、偏航角(yaw)和翻滚角(roll)表示 |
| 手势识别 | 检测和分类用户手部动作的过程 |
| 多模态融合 | 整合来自多个感知通道（模态）的信息以提高识别准确性的技术 |
| GazeCapture | 一个大规模的用于眼动追踪研究的公开数据集 |
| OTA更新 | Over-The-Air更新，通过无线网络进行软件更新 |
| ASIL | Automotive Safety Integrity Level，汽车安全完整性等级 |

### 9.2 相关标准

1. ISO 26262: 道路车辆功能安全标准
2. ISO 15005: 道路车辆-交通信息和控制系统的人机接口
3. GDPR: 欧盟通用数据保护条例
4. SAE J3016: 自动驾驶系统分级标准
5. ISO 2575: 道路车辆-控制器、指示器和信号的符号

### 9.3 参考文献

1. Krafka, K., Khosla, A., Kellnhofer, P., et al. (2016). "Eye Tracking for Everyone." IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
2. Fridman, L., Langhans, P., Lee, J., & Reimer, B. (2016). "Driver Gaze Region Estimation without Use of Eye Movement." IEEE Intelligent Systems.
3. 车载人机交互系统安全指南 (2023). 中国汽车工程学会.
4. 智能网联汽车人机交互技术规范 (2022). 中国汽车技术研究中心.